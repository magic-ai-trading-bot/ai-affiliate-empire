# Service Level Objectives (SLOs) & Monitoring Strategy

**Generated**: 2025-10-31
**Project**: AI Affiliate Empire
**Version**: 1.0
**Review Cycle**: Quarterly

---

## Executive Summary

This document defines Service Level Objectives (SLOs) based on comprehensive load testing results that demonstrate:
- **Zero errors** across 125,000+ requests
- **p95 response time** of 175ms under stress (200 VUs)
- **100% uptime** during all test scenarios
- **Excellent spike recovery** (<120s)

SLOs are set to maintain this exceptional performance while allowing reasonable operational margin.

---

## 1. Service Level Indicators (SLIs)

### Definition
SLIs are quantitative measures of service level. We measure these continuously to evaluate performance against SLOs.

### Primary SLIs

#### 1.1 Availability
**Definition**: Percentage of successful HTTP requests (status 2xx/3xx vs. 5xx)

**Measurement**:
```
Availability = (Successful Requests / Total Requests) Ã— 100%
```

**Current Performance**: 100% (0 errors in 125K requests)

---

#### 1.2 Latency
**Definition**: Time from request received to response sent

**Measurements**:
- **p50 (median)**: 50% of requests faster than this
- **p95**: 95% of requests faster than this
- **p99**: 99% of requests faster than this

**Current Performance**:
- p50: 83ms
- p95: 175ms
- p99: ~200ms

---

#### 1.3 Throughput
**Definition**: Number of requests successfully processed per second

**Measurement**:
```
Throughput = Successful Requests / Time Period
```

**Current Performance**: 61 req/s at 200 VUs

---

#### 1.4 Error Rate
**Definition**: Percentage of requests resulting in errors

**Measurement**:
```
Error Rate = (Failed Requests / Total Requests) Ã— 100%
```

**Current Performance**: 0.00%

---

## 2. Service Level Objectives (SLOs)

### SLO Framework

SLOs are set using the **4-9s availability framework**:
- **99.9%** (three nines): ~43 minutes downtime/month
- **99.95%**: ~21 minutes downtime/month
- **99.99%** (four nines): ~4 minutes downtime/month

### Our SLO Targets

#### 2.1 Availability SLO
```yaml
Objective: 99.9% availability over 30-day window
Measurement Window: Rolling 30 days
Error Budget: 0.1% = ~43 minutes/month = ~10 hours/year

Acceptable Errors: 1 in 1,000 requests
```

**Rationale**:
- Load testing showed 100% availability
- 99.9% allows operational margin
- Industry standard for non-critical services
- Achievable with single instance

**Error Budget Usage**:
```
Monthly Budget: 43 minutes downtime
- Planned Maintenance: 20 minutes (1x/month)
- Unplanned Incidents: 23 minutes buffer
```

---

#### 2.2 Latency SLO
```yaml
Objective: p95 response time < 500ms
Measurement Window: Rolling 24 hours
Target: 95% of requests < 500ms

Stretch Goal: p95 < 300ms
```

**Rationale**:
- Load testing p95: 175ms (excellent)
- 500ms target allows 2.8x margin
- Meets user expectation for web apps
- Above industry standard (1-2 seconds)

**Per-Endpoint Targets**:

| Endpoint Type | p95 Target | Justification |
|---------------|------------|---------------|
| Health Check | < 100ms | Simple, no DB query |
| Product List | < 300ms | Database query, caching helps |
| Analytics | < 500ms | Complex aggregations |
| Product Sync | < 2000ms | Bulk operation, less frequent |
| Video Generate | < 10s | AI processing, async acceptable |

---

#### 2.3 Error Rate SLO
```yaml
Objective: Error rate < 0.5% over 24-hour window
Measurement Window: Rolling 24 hours
Target: < 5 errors per 1,000 requests

Stretch Goal: < 0.1% (1 in 1,000)
```

**Rationale**:
- Load testing: 0% error rate
- 0.5% allows for edge cases
- Covers: database errors, timeouts, dependency failures
- Industry standard: 1-5%

**Error Classification**:

| Error Type | Budget Allocation | Acceptable Rate |
|------------|------------------|-----------------|
| Client Errors (4xx) | Not counted | Unlimited |
| Server Errors (5xx) | Primary budget | < 0.5% |
| Timeout Errors | Secondary budget | < 0.1% |
| Dependency Failures | Tertiary budget | < 0.2% |

---

#### 2.4 Throughput SLO
```yaml
Objective: Support 50 req/s sustained throughput
Measurement Window: Rolling 1 hour
Target: Average > 50 req/s during peak hours

Capacity: 61 req/s tested (22% headroom)
```

**Rationale**:
- Load testing: 61 req/s at 200 VUs
- 50 req/s allows 22% safety margin
- Expected production: 5-10 req/s
- 5-10x capacity buffer

**Load Classification**:

| Load Level | Requests/Second | Expected Scenario |
|------------|----------------|-------------------|
| Idle | < 1 | Off-peak hours |
| Normal | 1-10 | Business hours |
| Elevated | 10-30 | Popular content |
| High | 30-50 | Viral content |
| **SLO Limit** | **50** | **Sustained max** |
| Tested Max | 61 | Stress test result |

---

## 3. Service Level Agreements (SLAs)

### Internal SLAs (Development Team)

#### 3.1 Response Time Commitment
```
- 95% of requests: < 500ms (matches SLO)
- 99% of requests: < 1000ms
- 100% of requests: < 5000ms (timeout)
```

#### 3.2 Availability Commitment
```
- Monthly: 99.9% availability
- Yearly: 99.9% availability
- Planned downtime: < 30 minutes/month (announced 48h prior)
```

#### 3.3 Data Durability
```
- Database backups: Daily (retained 30 days)
- Recovery Point Objective (RPO): < 24 hours
- Recovery Time Objective (RTO): < 4 hours
```

---

### External SLAs (Future - for Enterprise Customers)

```yaml
Tier 1 (Free):
  availability: 99.5%
  support: Community
  sla_credits: None

Tier 2 (Pro - $99/month):
  availability: 99.9%
  support: Email (24h response)
  sla_credits: 10% monthly fee per 0.1% below SLA

Tier 3 (Enterprise - $499/month):
  availability: 99.95%
  support: Priority (4h response)
  sla_credits: 25% monthly fee per 0.1% below SLA
```

---

## 4. Monitoring & Alerting Strategy

### 4.1 Monitoring Stack

#### Primary Monitoring
```
Application: Sentry (APM + Error Tracking)
Infrastructure: Grafana + Prometheus
Uptime: UptimeRobot (external checks)
Logs: Winston + CloudWatch/Loki
```

#### Metrics Collection
```typescript
// Collect these metrics every 30 seconds
const metrics = {
  // RED metrics (Rate, Errors, Duration)
  'http.request.rate': gauge,
  'http.request.errors': counter,
  'http.request.duration': histogram,

  // USE metrics (Utilization, Saturation, Errors)
  'system.cpu.usage': gauge,
  'system.memory.usage': gauge,
  'db.connections.active': gauge,
  'db.connections.waiting': gauge,

  // Business metrics
  'products.active': gauge,
  'videos.generated.today': counter,
  'revenue.today': counter,
};
```

---

### 4.2 Alerting Rules

#### Critical Alerts (Page On-Call)

```yaml
critical_alerts:
  - name: High Error Rate
    condition: error_rate > 1% for 2 minutes
    severity: critical
    action: Page on-call engineer
    escalation: 5 minutes to manager

  - name: Service Down
    condition: availability < 99% for 1 minute
    severity: critical
    action: Page on-call engineer
    escalation: 3 minutes to manager

  - name: Extreme Latency
    condition: p95_latency > 2000ms for 2 minutes
    severity: critical
    action: Page on-call engineer
    escalation: 5 minutes to manager

  - name: Database Unavailable
    condition: db_connection_error for 30 seconds
    severity: critical
    action: Page on-call engineer
    escalation: Immediate to manager
```

#### Warning Alerts (Notify Team)

```yaml
warning_alerts:
  - name: Elevated Error Rate
    condition: error_rate > 0.5% for 5 minutes
    severity: warning
    action: Slack notification
    escalation: None

  - name: High Latency
    condition: p95_latency > 500ms for 5 minutes
    severity: warning
    action: Slack notification
    escalation: None

  - name: High CPU Usage
    condition: cpu_usage > 70% for 10 minutes
    severity: warning
    action: Slack notification
    escalation: None

  - name: High Memory Usage
    condition: memory_usage > 700MB for 10 minutes
    severity: warning
    action: Slack notification
    escalation: None

  - name: Connection Pool Saturation
    condition: db_connections > 40 for 5 minutes
    severity: warning
    action: Slack notification
    escalation: None
```

#### Info Alerts (Monitor)

```yaml
info_alerts:
  - name: Elevated Traffic
    condition: request_rate > 30 req/s for 15 minutes
    severity: info
    action: Log to dashboard
    escalation: None

  - name: Slow Query Detected
    condition: query_duration > 1000ms
    severity: info
    action: Log to slow query log
    escalation: None

  - name: Cache Miss Rate High
    condition: cache_miss_rate > 40% for 15 minutes
    severity: info
    action: Log to dashboard
    escalation: None
```

---

### 4.3 Dashboard Configuration

#### Real-time Dashboard (60-second refresh)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸŽ¯ SLO Compliance                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Availability:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 99.95%  âœ…      â”‚
â”‚ Latency (p95): â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  482ms      âœ…      â”‚
â”‚ Error Rate:    â–ˆâ–ˆ 0.12%                        âœ…      â”‚
â”‚ Throughput:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  52 req/s          âœ…      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“Š Response Time Distribution (24h)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ p50:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  85ms                                  â”‚
â”‚ p95:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  172ms                        â”‚
â”‚ p99:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  210ms                   â”‚
â”‚ Max:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  245ms                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ”¥ Current Load        â”‚ âš ï¸  Error Budget (30d)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request Rate: 8.2 req/sâ”‚ Used: 12 min / 43 min         â”‚
â”‚ Active Users: 23       â”‚ Remaining: 72%                â”‚
â”‚ Avg Latency: 92ms      â”‚ Burn Rate: 0.4 min/day        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Error Budget Policy

### What is an Error Budget?

Error budget is the acceptable amount of downtime/errors before SLO is violated.

**Calculation**:
```
Error Budget = 100% - SLO Target
For 99.9% SLO: Error Budget = 0.1%

Monthly Budget:
= 0.1% Ã— 30 days Ã— 24 hours Ã— 60 minutes
= 43.2 minutes of downtime allowed per month
```

---

### Error Budget Usage Tracking

#### Budget Allocation
```yaml
Total Budget: 43 minutes/month

Allocation:
  planned_maintenance: 20 minutes (47%)
  unplanned_incidents: 23 minutes (53%)
  buffer: 0 minutes (0%)

Reserve Policy:
  - Keep 10 minutes reserve for emergencies
  - Unused budget does not roll over
```

---

### Error Budget Policies

#### When Budget > 50% Remaining
```yaml
Status: Healthy
Actions:
  - Continue normal operations
  - Deploy during business hours
  - Experiment with new features
  - Perform optional maintenance
```

#### When Budget 20-50% Remaining
```yaml
Status: Caution
Actions:
  - Reduce deployment frequency
  - Deploy only during off-peak hours
  - Increase code review rigor
  - Postpone risky changes
  - Review recent incidents
```

#### When Budget < 20% Remaining
```yaml
Status: Critical
Actions:
  - Freeze all non-critical deployments
  - Cancel planned maintenance
  - Focus on stability improvements
  - Root cause analysis required
  - Manager approval for any changes
  - Incident review meeting
```

#### When Budget Exhausted (0%)
```yaml
Status: SLO Violated
Actions:
  - Immediate deployment freeze
  - Postmortem required
  - Executive escalation
  - Focus only on reliability improvements
  - Review monitoring and alerting
  - Consider architecture changes
```

---

### Error Budget Burn Rate Alerts

```yaml
alerts:
  - name: Fast Burn Rate
    condition: "Burning 7 days budget in 1 hour"
    example: "6 minutes used in 1 hour"
    action: Page on-call immediately

  - name: Moderate Burn Rate
    condition: "Burning 30 days budget in 1 day"
    example: "43 minutes used in 24 hours"
    action: Warning notification

  - name: Slow Burn Rate
    condition: "On track to exceed 30-day budget"
    example: "> 1.4 minutes used per day"
    action: Info notification
```

---

## 6. Incident Response Plan

### Severity Levels

#### SEV-1: Critical (Page Immediately)
```
Definition:
  - Service completely down
  - Error rate > 5%
  - Data loss or corruption
  - Security breach

Response Time: < 15 minutes
Resolution Target: < 2 hours
On-call Required: Yes
Postmortem Required: Yes
```

#### SEV-2: High (Alert Team)
```
Definition:
  - Partial service degradation
  - Error rate 1-5%
  - SLO violated
  - Performance degradation > 2x

Response Time: < 30 minutes
Resolution Target: < 4 hours
On-call Required: Business hours only
Postmortem Required: Yes
```

#### SEV-3: Medium (Monitor)
```
Definition:
  - Minor degradation
  - Error rate 0.5-1%
  - Approaching SLO limit
  - Single feature affected

Response Time: < 2 hours
Resolution Target: < 24 hours
On-call Required: No
Postmortem Required: Optional
```

#### SEV-4: Low (Track)
```
Definition:
  - Cosmetic issues
  - Non-critical bugs
  - Error rate < 0.5%
  - Edge cases

Response Time: < 1 day
Resolution Target: < 1 week
On-call Required: No
Postmortem Required: No
```

---

### Incident Response Playbook

#### Step 1: Detect (0-5 minutes)
```
1. Alert triggered or user report received
2. Check monitoring dashboard
3. Verify incident is real (not false positive)
4. Determine severity level
```

#### Step 2: Respond (5-15 minutes)
```
1. Acknowledge alert
2. Create incident ticket
3. Notify team via Slack (#incidents)
4. Assign incident commander
5. Start incident log
```

#### Step 3: Investigate (15-30 minutes)
```
1. Check application logs
2. Review recent deployments
3. Check database status
4. Check external dependencies
5. Identify root cause hypothesis
```

#### Step 4: Mitigate (30-60 minutes)
```
1. Implement temporary fix if available
   - Rollback deployment
   - Restart service
   - Scale up resources
   - Enable maintenance mode
2. Monitor for improvement
3. Update incident ticket
```

#### Step 5: Resolve (1-4 hours)
```
1. Implement permanent fix
2. Deploy fix
3. Verify resolution
4. Monitor for stability
5. Update incident ticket
6. Notify stakeholders
```

#### Step 6: Postmortem (Within 48 hours)
```
1. Document incident timeline
2. Identify root cause
3. List action items
4. Assign owners
5. Schedule follow-up
6. Update runbooks
```

---

## 7. Performance Review Cadence

### Daily (Automated)
```
What: Automated checks
Who: Monitoring system
Output: Alerts if thresholds exceeded

Checks:
  - SLO compliance status
  - Error budget burn rate
  - Resource utilization trends
```

### Weekly (10 minutes)
```
What: Quick health check
Who: Engineering team
Output: Status update in Slack

Review:
  - SLO compliance (all green?)
  - Error budget remaining
  - Notable incidents
  - Resource trends
```

### Monthly (1 hour)
```
What: Performance deep dive
Who: Engineering + Product
Output: Monthly report + action items

Review:
  - SLO compliance by service
  - Error budget usage
  - Incident trends
  - Performance optimization opportunities
  - Capacity planning
  - Cost optimization
```

### Quarterly (2 hours)
```
What: Strategic review
Who: Engineering + Product + Exec
Output: Quarterly report + roadmap update

Review:
  - SLO adjustments needed?
  - Architecture changes required?
  - Scaling strategy
  - Budget vs. actuals
  - Feature impact on performance
  - Industry benchmarks
```

---

## 8. SLO Review & Update Process

### When to Review SLOs

1. **After Major Incidents**
   - SLO violated multiple times
   - Unrealistic SLO discovered
   - New failure modes identified

2. **Quarterly Schedule**
   - Standard review cycle
   - Compare actuals vs. targets
   - Adjust based on business needs

3. **After Architecture Changes**
   - New services added
   - Technology stack changes
   - Scaling strategy changes

4. **Business Requirement Changes**
   - New customer segments
   - New SLA requirements
   - Competitive pressure

---

### SLO Update Criteria

#### Tighten SLO (Make More Strict) When:
```
âœ“ Consistently beating target by >20%
âœ“ User expectations have increased
âœ“ Competitive pressure
âœ“ Moving upmarket to enterprise
```

#### Relax SLO (Make Less Strict) When:
```
âœ“ Consistently missing target
âœ“ Unrealistic given constraints
âœ“ Cost to achieve is prohibitive
âœ“ User satisfaction remains high
```

---

## 9. Implementation Checklist

### Phase 1: Foundation (Week 1)
- [ ] Set up Sentry APM
- [ ] Configure Grafana dashboard
- [ ] Implement health check endpoint
- [ ] Set up UptimeRobot external monitoring
- [ ] Create #incidents Slack channel

### Phase 2: Alerting (Week 2)
- [ ] Configure critical alerts
- [ ] Configure warning alerts
- [ ] Test alert escalation
- [ ] Document on-call rotation
- [ ] Create incident playbook

### Phase 3: Dashboards (Week 3)
- [ ] Build SLO compliance dashboard
- [ ] Build error budget dashboard
- [ ] Build service health dashboard
- [ ] Set up automated reports
- [ ] Train team on dashboards

### Phase 4: Process (Week 4)
- [ ] Establish review cadence
- [ ] Schedule first monthly review
- [ ] Create postmortem template
- [ ] Document incident response process
- [ ] Assign ownership

---

## 10. Success Metrics

### How We Measure SLO Program Success

#### Month 1 Goals
```
âœ“ All SLIs being collected
âœ“ Dashboards operational
âœ“ Alerts configured and tested
âœ“ Team trained on process
```

#### Month 3 Goals
```
âœ“ 0 missed SLO violations (100% caught by alerts)
âœ“ Average incident response time < 30 minutes
âœ“ 90% of incidents resolved within SLA
âœ“ 3 monthly reviews completed
```

#### Month 6 Goals
```
âœ“ 99%+ SLO compliance
âœ“ <20% error budget used
âœ“ 0 undetected outages
âœ“ Average MTTR < 1 hour
âœ“ Proactive capacity planning in place
```

---

## Appendix: Quick Reference

### SLO Targets Summary
```
Availability:  99.9%  (43 min/month downtime allowed)
Latency (p95): <500ms (95% of requests)
Error Rate:    <0.5%  (5 errors per 1,000 requests)
Throughput:    >50 req/s (sustained)
```

### Critical Contacts
```
On-Call Engineer: [Rotation Schedule]
Engineering Manager: [Contact Info]
Product Manager: [Contact Info]
CTO: [Contact Info]
```

### Important Links
```
Dashboard: https://grafana.ai-affiliate-empire.com
Sentry: https://sentry.io/ai-affiliate-empire
Runbooks: https://wiki.ai-affiliate-empire.com/runbooks
Postmortems: https://wiki.ai-affiliate-empire.com/postmortems
```

---

**Document Owner**: Engineering Team
**Last Review**: 2025-10-31
**Next Review**: 2026-01-31 (Quarterly)
**Version**: 1.0

